# Aplicação do modelo - É importante que seja rodado na versão 9.13 do Carla

#todas as importações
import glob
import os
import carla #biblioteca do Carla
import time # para definir um atraso depois de cada foto
import cv2 #para trabalhar com as imagens geradas pela câmera
import numpy as np #para alterar a representação da imagem - remodelar
import math
from math import pi
import sys
try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
    sys.path.insert(0,'C:/CARLA/carla/PythonAPI/carla')
except IndexError:
    pass
import random
import json

from matplotlib import pyplot as plt
from agents.navigation.global_route_planner import GlobalRoutePlanner
from agents.navigation.global_route_planner_dao import GlobalRoutePlannerDAO
from tensorflow.python.keras.models import load_model
from tensorflow.python.keras.utils import *
from tensorflow.python.keras.models import model_from_json
PREFERRED_SPEED = 30
SPEED_THRESHOLD = 2 #defines when we get close to desired speed so we drop the

# Max. ângulo de esterçamento
MAX_STEER_DEGREES = 40

STEERING_CONVERSION = 75

CAMERA_POS_Z = 1.3 
CAMERA_POS_X = 1.4 

#Lembrar de reajustar imagens antes de rodar o programa

HEIGHT = 120
WIDTH = 380

MODEL_NAME = 'Modelo70K_2' #Altere para o nome do seu modelo
def select_route(start_point, end_point, max_distance=1000):
    '''
    Retorna uma rota entre o ponto de partida e o ponto de chegada fornecidos,
    limitada por uma distância máxima especificada.
    '''
    sampling_resolution = 1
    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)
    
    
    # Traçar a rota com base nas localizações
    route = grp.trace_route(start_point, end_point)
    
    if len(route) > 1:
       # Verificar se a distância da rota é menor que o limite máximo
       route_distance = sum([wp[0].distance(wp[1].transform.location) for wp in route])
    if route_distance <= max_distance:
            return route
    return None
# função para manter a velocidade constante
def maintain_speed(s):
    ''' 
    this is a very simple function to maintan desired speed
    s arg is actual current speed
    '''
    if s >= PREFERRED_SPEED:
        return 0
    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:
        return 0.9 # think of it as % of "full gas"
    else:
        return 0.4 # tweak this if the car is way over or under preferred speed

def get_angle(car,wp):
    '''
    this function returns degrees between the car's direction 
    and direction to a selected waypoint
    '''
    vehicle_pos = car.get_transform()
    car_x = vehicle_pos.location.x
    car_y = vehicle_pos.location.y
    wp_x = wp.transform.location.x
    wp_y = wp.transform.location.y
    
    
    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    
   
    car_vector = vehicle_pos.get_forward_vector()
    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))
    # extra checks on predicted angle when values close to 360 degrees are returned
    if degrees<-180:
        degrees = degrees + 360
    elif degrees > 180:
        degrees = degrees - 360
    return degrees
def get_proper_angle(car,wp_idx,rte):    
  
    next_angle_list = []
    for i in range(10):
        if wp_idx + i*3 <len(rte)-1:
            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))
    idx = 0
    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:
        idx +=1
    return wp_idx+idx*3,next_angle_list[idx] 
def get_distant_angle(car,wp_idx,rte, delta):
    
    if wp_idx + delta < len(rte)-1:
        i = wp_idx + delta
    else:
        i = len(rte)-1
    # checando cruzamentos na via
    intersection_detected = False
    for x in range(i-wp_idx):
        if rte[wp_idx+x][0].is_junction:
             intersection_detected = True
    angle = get_angle(car,rte[i][0])
    if not intersection_detected:
        result = 0
    elif angle <-10:
        result = -1
    elif angle>10:
        result =1
    else:
        result = 0    
    return result
def predict_angle(sem_im,direction):
    
    img = np.float32(sem_im)
    img = img /255
    img = np.expand_dims(img, axis=0)
    #print('input shape: ',img.shape)
    angle = model([img,np.reshape(direction, (1, 1))],training=False)
    return  angle.numpy()[0][0]
def camera_callback(image,data_dict):
    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]

# Lista para armazenar as coordenadas de latitude e longitude
latitude_list = []
longitude_list = []

def gps_callback(data):
    if data is not None:
        latitude = data.transform.location.x
        longitude = data.transform.location.y
        altitude = data.transform.location.z

        # Adicionar as coordenadas à lista
        latitude_list.append(latitude)
        longitude_list.append(longitude)


# Função para câmera semântica 
def sem_callback(image,data_dict):
    image.convert(carla.ColorConverter.CityScapesPalette)
    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]
def draw_route(wp, route,seconds=3.0):
    
    if len(route)-wp <25: # route within 25 points from end is red
        draw_colour = carla.Color(r=255, g=0, b=0)
    else:
        draw_colour = carla.Color(r=0, g=0, b=255)
    for i in range(10):
        if wp+i<len(route)-2:
            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,
                color=draw_colour, life_time=seconds,
                persistent_lines=True)
    return None
def exit_clean():
    #clean up
    cv2.destroyAllWindows()
    camera.stop()
    for sensor in world.get_actors().filter('*sensor*'):
        sensor.destroy()
    for actor in world.get_actors().filter('*vehicle*'):
        actor.destroy()
    return None

#Mudar de cidade caso queira


client = carla.Client('localhost', 2000)
client.set_timeout(5)
client.load_world('Town03')

client = carla.Client('localhost', 2000)

# Iniciar carro no ambiente
world = client.get_world()

# Obtenha a biblioteca de plantas e os pontos de desova para o mapa
bp_lib = world.get_blueprint_library() 
spawn_points = world.get_map().get_spawn_points()

# Limpar tudo
for actor in world.get_actors().filter('*vehicle*'):
    actor.destroy()
    
# Informaçoes do mapa
map = world.get_map() # Informaçoes do mapa 

## Adiciona o veiculo

# Obtenha a planta do veículo que você deseja
vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020') 

# Escolhendo especificamente onde vai ficar o veículo
start_point = spawn_points[82]
end_point = spawn_points [22]

# inserir o veículo  
vehicle = world.try_spawn_actor(vehicle_bp, start_point)
# Chamadas para criar GPS e acoplar ao veículo
gps_bp = world.get_blueprint_library().find('sensor.other.gnss')
gps_transform = carla.Transform(carla.Location(x=20, y=10, z=4), carla.Rotation())  # Ajuste a localização conforme necessário
gps_sensor = world.spawn_actor(gps_bp, gps_transform, attach_to=vehicle)

# Adicionando o callback ao sensor GPS
gps_sensor.listen(gps_callback)
# Mova o espectador para atrás do veículo
spectator = world.get_spectator()
transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) 
spectator.set_transform(transform) 


# Traça o caminho
point_a = start_point.location
sampling_resolution = 1
grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)

# Ponto inicial
a = vehicle.get_location()

# Ponto final
b = spawn_points[22].location


w1 = grp.trace_route(a, b) # Refencia 

# Plotar rota
x = [i[0].transform.location.x for i in w1]
y = [i[0].transform.location.y for i in w1]
plt.plot(y, x)
plt.axis('Equal')
plt.plot(a.y, a.x, 'x', label='Início')
plt.plot(b.y, b.x, 'o', label='Fim')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Rota definida por GPS')
plt.legend()
plt.grid()
plt.show()

distance = 0
for loc in spawn_points: # we start trying all spawn points 
                            #but we just exclude first at zero index
    cur_route = grp.trace_route(point_a, loc.location)
    if len(cur_route)>distance:
        distance = len(cur_route)
        route = cur_route

# Definindo câmera RGB
camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')
camera_bp.set_attribute('image_size_x', '640') 
camera_bp.set_attribute('image_size_y', '360')
camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))
#this creates the camera in the sim
camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)

image_w = camera_bp.get_attribute('image_size_x').as_int()
image_h = camera_bp.get_attribute('image_size_y').as_int()

camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')
camera_bp.set_attribute('fov', '90')
camera_bp.set_attribute('image_size_x', '640') 
camera_bp.set_attribute('image_size_y', '360')
camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))
camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)

image_w = 640
image_h = 360

camera_data = {'sem_image': np.zeros((image_h,image_w,4)),
               'image': np.zeros((image_h,image_w,4))}

# Abrindo a câmera acoplada na visão do motorista
camera.listen(lambda image: camera_callback(image,camera_data))
camera_sem.listen(lambda image: sem_callback(image,camera_data))
cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)
cv2.imshow('RGB Camera',camera_data['image'])

image = camera_data['image']
sem_image = camera_data['sem_image']
        
sem_image = cv2.resize(sem_image, (WIDTH,HEIGHT))

#loop principal
model = load_model(MODEL_NAME,compile=False)
model.compile()
quit= False 

curr_wp = 5 
predicted_angle = 0
PREFERRED_SPEED = 30

while curr_wp < len(route) - 1:
    # Carla Tick
    world.tick()

    # Verifique se a tecla 'q' foi pressionada para sair
    if cv2.waitKey(1) == ord('q'):
        quit = True
        exit_clean()
        break
    
    image = camera_data['image']
    sem_image = camera_data['sem_image']
    
    sem_image = cv2.resize(sem_image, (WIDTH, HEIGHT))

    # Verifique se o veículo está perto do final da rota
    if curr_wp >= len(route) - 10:  
        PREFERRED_SPEED = 0  
        exit_clean()
        break

    # Move para o próximo waypoint se estivermos muito perto
    while curr_wp < len(route) -2  and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:
        curr_wp += 1

    # Obtenha o próximo waypoint e o ângulo predito
    curr_wp, predicted_angle = get_proper_angle(vehicle, curr_wp, route)
    distant_angle = get_distant_angle(vehicle, curr_wp, route, 30)

    # Obtenha a velocidade atual do veículo
    v = vehicle.get_velocity()
    speed = round(3.6 * math.sqrt(v.x ** 2 + v.y ** 2 + v.z ** 2), 0)

    # Aplique a velocidade preferida para manter a velocidade desejada
    estimated_throttle = maintain_speed(speed)

    # Use o modelo para prever o ângulo de direção
    steer_input = predict_angle(sem_image, distant_angle)

    # Aplique os controles do veículo
    vehicle.apply_control(carla.VehicleControl(throttle=float(estimated_throttle), steer=float(steer_input)))

    cv2.imshow('RGB Camera', image)

    if quit:
        break
#clean up
for actor in world.get_actors().filter('*vehicle*'):
    actor.destroy()

# Plotar o caminho percorrido pelo carro
plt.figure(figsize=(8, 6))
plt.plot(longitude_list, latitude_list, marker='o', linestyle='-', color='g')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Caminho Percorrido pelo Carro')
plt.grid(True)
plt.show()

#Visualizar a última captura semântica da câmera
plt.imshow(sem_image)
plt.title('Sem_image')
plt.show()
