# Aplicação do modelo - É importante que seja rodado na versão 9.13 do Carla

#all imports
import glob
import os
import carla #biblioteca do Carla
import time # para definir um atraso depois de cada foto
import cv2 #para trabalhar com as imagens geradas pela câmera
import numpy as np #para alterar a representação da imagem - remodelar
import math
from math import pi
import sys
try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
    sys.path.insert(0,'C:/CARLA/carla/PythonAPI/carla')
except IndexError:
    pass
import random
import json

from matplotlib import pyplot as plt
from agents.navigation.global_route_planner import GlobalRoutePlanner
from agents.navigation.global_route_planner_dao import GlobalRoutePlannerDAO
from tensorflow.python.keras.models import load_model
from tensorflow.python.keras.utils import *
from tensorflow.python.keras.models import model_from_json
PREFERRED_SPEED = 30
SPEED_THRESHOLD = 2 #defines when we get close to desired speed so we drop the

# Max steering angle
MAX_STEER_DEGREES = 40
# This is max actual angle with Mini under steering input=1.0
STEERING_CONVERSION = 75

CAMERA_POS_Z = 1.3 
CAMERA_POS_X = 1.4 

# resize images before running thgem through the model
# this is the same as when yo train the model
HEIGHT = 120
WIDTH = 380

MODEL_NAME = 'Modelo70K_2' #Altere para o nome do seu modelo
def select_route(start_point, end_point, max_distance=1000):
    '''
    Retorna uma rota entre o ponto de partida e o ponto de chegada fornecidos,
    limitada por uma distância máxima especificada.
    '''
    sampling_resolution = 1
    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)
    
    
    # Traçar a rota com base nas localizações
    route = grp.trace_route(start_point, end_point)
    
    if len(route) > 1:
       # Verificar se a distância da rota é menor que o limite máximo
       route_distance = sum([wp[0].distance(wp[1].transform.location) for wp in route])
    if route_distance <= max_distance:
            return route
    return None
# maintain speed function
def maintain_speed(s):
    ''' 
    this is a very simple function to maintan desired speed
    s arg is actual current speed
    '''
    if s >= PREFERRED_SPEED:
        return 0
    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:
        return 0.9 # think of it as % of "full gas"
    else:
        return 0.4 # tweak this if the car is way over or under preferred speed
# function to get angle between the car and target waypoint
def get_angle(car,wp):
    '''
    this function returns degrees between the car's direction 
    and direction to a selected waypoint
    '''
    vehicle_pos = car.get_transform()
    car_x = vehicle_pos.location.x
    car_y = vehicle_pos.location.y
    wp_x = wp.transform.location.x
    wp_y = wp.transform.location.y
    
    # vector to waypoint
    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    
    #car vector
    car_vector = vehicle_pos.get_forward_vector()
    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))
    # extra checks on predicted angle when values close to 360 degrees are returned
    if degrees<-180:
        degrees = degrees + 360
    elif degrees > 180:
        degrees = degrees - 360
    return degrees
def get_proper_angle(car,wp_idx,rte):
    '''
    This function uses simple fuction above to get angle but for current
    waypoint and a few more next waypoints to ensure we have not skipped
    next waypoint so we avoid the car trying to turn back
    '''
    # create a list of angles to next 5 waypoints starting with current
    next_angle_list = []
    for i in range(10):
        if wp_idx + i*3 <len(rte)-1:
            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))
    idx = 0
    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:
        idx +=1
    return wp_idx+idx*3,next_angle_list[idx] 
def get_distant_angle(car,wp_idx,rte, delta):
    '''
    This function modifies the fuction above to get angle to a waypoint
    at a distance so we could use it for training image generation
    
    We will display the angle for now in the 'telemetry' view so
    we could play with how far forward we need to pick the waypoint
    '''
    if wp_idx + delta < len(rte)-1:
        i = wp_idx + delta
    else:
        i = len(rte)-1
    # check for intersection within the "look forward"
    # so we do not give turn results when just following the road
    intersection_detected = False
    for x in range(i-wp_idx):
        if rte[wp_idx+x][0].is_junction:
             intersection_detected = True
    angle = get_angle(car,rte[i][0])
    if not intersection_detected:
        result = 0
    elif angle <-10:
        result = -1
    elif angle>10:
        result =1
    else:
        result = 0    
    return result
def predict_angle(sem_im,direction):
    # tweaks for prediction
    img = np.float32(sem_im)
    img = img /255
    img = np.expand_dims(img, axis=0)
    #print('input shape: ',img.shape)
    angle = model([img,np.reshape(direction, (1, 1))],training=False)
    return  angle.numpy()[0][0]
def camera_callback(image,data_dict):
    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]

# utility function for camera listening 
def sem_callback(image,data_dict):
    image.convert(carla.ColorConverter.CityScapesPalette)
    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]
def draw_route(wp, route,seconds=3.0):
    #draw the next few points route in sim window - Note it does not
    # get into the camera of the car
    if len(route)-wp <25: # route within 25 points from end is red
        draw_colour = carla.Color(r=255, g=0, b=0)
    else:
        draw_colour = carla.Color(r=0, g=0, b=255)
    for i in range(10):
        if wp+i<len(route)-2:
            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,
                color=draw_colour, life_time=seconds,
                persistent_lines=True)
    return None
def exit_clean():
    #clean up
    cv2.destroyAllWindows()
    camera.stop()
    for sensor in world.get_actors().filter('*sensor*'):
        sensor.destroy()
    for actor in world.get_actors().filter('*vehicle*'):
        actor.destroy()
    return None

#Mudar de cidade caso queira


client = carla.Client('localhost', 2000)
client.set_timeout(5)
client.load_world('Town03')

client = carla.Client('localhost', 2000)
# start a car
world = client.get_world()

# Obtenha a biblioteca de plantas e os pontos de desova para o mapa
bp_lib = world.get_blueprint_library() 
spawn_points = world.get_map().get_spawn_points()

#clean up
for actor in world.get_actors().filter('*vehicle*'):
    actor.destroy()
    
# Informaçoes do mapa
map = world.get_map() # Informaçoes do mapa 
## Adiciona o veiculo

# Obtenha a planta do veículo que você deseja
vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020') 

# Escolhendo especificamente onde vai ficar o veículo
start_point = spawn_points[82]
end_point = spawn_points [22]

# inserir o veículo  
vehicle = world.try_spawn_actor(vehicle_bp, start_point)
# Chamadas para criar GPS e acoplar ao veículo
gps_bp = world.get_blueprint_library().find('sensor.other.gnss')
gps_transform = carla.Transform(carla.Location(x=20, y=10, z=4), carla.Rotation())  # Ajuste a localização conforme necessário
gps_sensor = world.spawn_actor(gps_bp, gps_transform, attach_to=vehicle)

# Adicionando o callback ao sensor GPS
gps_sensor.listen(gps_callback)
# Mova o espectador para atrás do veículo
spectator = world.get_spectator()
transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) 
spectator.set_transform(transform) 


# Traça o caminho
point_a = start_point.location
sampling_resolution = 1
grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)

# Ponto inicial
a = vehicle.get_location()

# Ponto final
b = spawn_points[22].location


w1 = grp.trace_route(a, b) # Refencia 

# Plot route
x = [i[0].transform.location.x for i in w1]
y = [i[0].transform.location.y for i in w1]
plt.plot(y, x)
plt.axis('Equal')
plt.plot(a.y, a.x, 'x', label='Início')
plt.plot(b.y, b.x, 'o', label='Fim')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Rota definida por GPS')
plt.legend()
plt.grid()
plt.show()

# now let' pick the longest possible route
distance = 0
for loc in spawn_points: # we start trying all spawn points 
                            #but we just exclude first at zero index
    cur_route = grp.trace_route(point_a, loc.location)
    if len(cur_route)>distance:
        distance = len(cur_route)
        route = cur_route
#setting RGB Camera - this follow the approach explained in a Carla video
camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')
camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows
camera_bp.set_attribute('image_size_y', '360')
camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))
#this creates the camera in the sim
camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)

image_w = camera_bp.get_attribute('image_size_x').as_int()
image_h = camera_bp.get_attribute('image_size_y').as_int()

camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')
camera_bp.set_attribute('fov', '90')
camera_bp.set_attribute('image_size_x', '640') 
camera_bp.set_attribute('image_size_y', '360')
camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))
camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)

image_w = 640
image_h = 360

camera_data = {'sem_image': np.zeros((image_h,image_w,4)),
               'image': np.zeros((image_h,image_w,4))}

# this actually opens a live stream from the camera
camera.listen(lambda image: camera_callback(image,camera_data))
camera_sem.listen(lambda image: sem_callback(image,camera_data))
cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)
cv2.imshow('RGB Camera',camera_data['image'])

image = camera_data['image']
sem_image = camera_data['sem_image']
        
sem_image = cv2.resize(sem_image, (WIDTH,HEIGHT))

#main loop
model = load_model(MODEL_NAME,compile=False)
model.compile()
quit= False 

curr_wp = 5 #we will be tracking waypoints in the route and switch to next one wen we get close to current one
predicted_angle = 0
PREFERRED_SPEED = 30 # setting speed at start of new route

while curr_wp < len(route) - 1:
    # Carla Tick
    world.tick()
    #draw_route(curr_wp, route, 1)

    # Verifique se a tecla 'q' foi pressionada para sair
    if cv2.waitKey(1) == ord('q'):
        quit = True
        exit_clean()
        break
    
    image = camera_data['image']
    sem_image = camera_data['sem_image']
    
    sem_image = cv2.resize(sem_image, (WIDTH, HEIGHT))

    # Verifique se o veículo está perto do final da rota
    if curr_wp >= len(route) - 10:  # within 10 points of end, the route is done
        PREFERRED_SPEED = 0  # setting speed to 0 after completing one route
        exit_clean()
        break

    # Move para o próximo waypoint se estivermos muito perto
    while curr_wp < len(route) -2  and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:
        curr_wp += 1

    # Obtenha o próximo waypoint e o ângulo predito
    curr_wp, predicted_angle = get_proper_angle(vehicle, curr_wp, route)
    distant_angle = get_distant_angle(vehicle, curr_wp, route, 30)

    # Obtenha a velocidade atual do veículo
    v = vehicle.get_velocity()
    speed = round(3.6 * math.sqrt(v.x ** 2 + v.y ** 2 + v.z ** 2), 0)

    # Aplique a velocidade preferida para manter a velocidade desejada
    estimated_throttle = maintain_speed(speed)

    # Use o modelo para prever o ângulo de direção
    steer_input = predict_angle(sem_image, distant_angle)

    # Aplique os controles do veículo
    vehicle.apply_control(carla.VehicleControl(throttle=float(estimated_throttle), steer=float(steer_input)))

    cv2.imshow('RGB Camera', image)

    if quit:
        break
#clean up
for actor in world.get_actors().filter('*vehicle*'):
    actor.destroy()

# Plotar o caminho percorrido pelo carro
plt.figure(figsize=(8, 6))
plt.plot(longitude_list, latitude_list, marker='o', linestyle='-', color='g')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Caminho Percorrido pelo Carro')
plt.grid(True)
plt.show()

#Visualizar a última captura semântica da câmera
plt.imshow(sem_image)
plt.title('Sem_image')
plt.show()
